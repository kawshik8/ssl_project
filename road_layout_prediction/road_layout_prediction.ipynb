{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box, compute_ts_road_map\n",
    "from modelzoo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VAE Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: vae\n",
      "Passed Input Size:torch.Size([3, 6, 3, 256, 306])\n",
      "----\n",
      "     Class: encoder\n",
      "     resnet_style: 18, pretrained: False\n",
      "     Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "     Output Size:torch.Size([3, 512, 8, 8])\n",
      "----\n",
      "Number of encoded states: 6, each of size: torch.Size([3, 512, 8, 8])\n",
      "Concatenated encoded states shape: torch.Size([3, 3072, 8, 8])\n",
      "----\n",
      "     Class: encoder_after_resnet\n",
      "     Passed Input Size:torch.Size([3, 3072, 8, 8])\n",
      "     Convolved Encoded state shape: torch.Size([3, 512, 4, 4])\n",
      "     Output Mean Size:torch.Size([3, 4096])\n",
      "     Output Var Size:torch.Size([3, 4096])\n",
      "----\n",
      "Output Mean Size:torch.Size([3, 4096])\n",
      "Output Var Size:torch.Size([3, 4096])\n",
      "Reparameterized Hidden State size: torch.Size([3, 4096])\n",
      "----\n",
      "     Class: vae_decoder\n",
      "     Passed Input Size:torch.Size([3, 4096])\n",
      "     Input recast into shape: torch.Size([3, 64, 8, 8])\n",
      "     Output Size:torch.Size([3, 800, 800])\n",
      "----\n",
      "Output Size:torch.Size([3, 800, 800])\n"
     ]
    }
   ],
   "source": [
    "model = vae()\n",
    "inp = torch.rand([3,6,3,256,306])\n",
    "model.summarize(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AE Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: autoencoder\n",
      "Passed Input Size:torch.Size([3, 6, 3, 256, 306])\n",
      "----\n",
      "     Class: encoder\n",
      "     resnet_style: 18, pretrained: False\n",
      "     Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "     Output Size:torch.Size([3, 512, 8, 8])\n",
      "----\n",
      "Number of encoded states: 6, each of size: torch.Size([3, 512, 8, 8])\n",
      "Concatenated Hidden State size: torch.Size([3, 3072, 8, 8])\n",
      "----\n",
      "     Class: decoder\n",
      "     Passed Input Size:torch.Size([3, 3072, 8, 8])\n",
      "     Output Size:torch.Size([3, 800, 800])\n",
      "----\n",
      "Output Size:torch.Size([3, 800, 800])\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "inp = torch.rand([3,6,3,256,306])\n",
    "model.summarize(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment and Model details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Type: ae\n",
      "ae Model Summary\n",
      "Class: autoencoder\n",
      "Passed Input Size:torch.Size([3, 6, 3, 256, 306])\n",
      "----\n",
      "     Class: encoder\n",
      "     resnet_style: 18, pretrained: False\n",
      "     Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "     Output Size:torch.Size([3, 512, 8, 8])\n",
      "----\n",
      "Number of encoded states: 6, each of size: torch.Size([3, 512, 8, 8])\n",
      "Concatenated Hidden State size: torch.Size([3, 3072, 8, 8])\n",
      "----\n",
      "     Class: decoder\n",
      "     Passed Input Size:torch.Size([3, 3072, 8, 8])\n",
      "     Output Size:torch.Size([3, 800, 800])\n",
      "----\n",
      "Output Size:torch.Size([3, 800, 800])\n",
      "Checking to restore...\n",
      "No checkpoint found at ./checkpoints/ae_checkpoint_4-24-res18-random.pth.tar\n"
     ]
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "seed = 8964\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "image_folder = '../data'\n",
    "annotation_csv = '../data/annotation.csv'\n",
    "\n",
    "#unlabeled_scene_index = np.arange(106)\n",
    "#labeled_scene_index = np.arange(106, 134)\n",
    "labeled_scene_index = np.arange(106, 132)\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "writer = SummaryWriter()\n",
    "\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "labeled_set = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=labeled_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "train_val_split_ratio = 0.85\n",
    "n=len(labeled_set)\n",
    "n_train=int(train_val_split_ratio*n)+1\n",
    "n_val=int((1-train_val_split_ratio)*n)\n",
    "assert n_train+n_val==n\n",
    "\n",
    "threshold = 0.5\n",
    "train_set, val_set = torch.utils.data.random_split(labeled_set, [n_train, n_val])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "dataloaders = {'train': train_loader, 'val': val_loader}\n",
    "\n",
    "\n",
    "model_types = ['ae','vae']\n",
    "model_choice = 0\n",
    "model_type = model_types[model_choice]\n",
    "\n",
    "print('Model Type: {0}'.format(model_type))\n",
    "\n",
    "resnet_style = '18'\n",
    "weights = 'random'\n",
    "\n",
    "if weights == 'random':\n",
    "    pretrained = False\n",
    "elif weights == 'imagenet':\n",
    "    pretrained = True\n",
    "elif weights == 'ssl':\n",
    "    pretrained = False\n",
    "    pass\n",
    "\n",
    "if model_type == 'ae':\n",
    "    model = autoencoder(resnet_style=resnet_style,pretrained=pretrained)\n",
    "elif model_type == 'vae':\n",
    "    model = vae(resnet_style=resnet_style,pretrained=pretrained)\n",
    "\n",
    "sample_input = torch.rand([3,6,3,256,306])\n",
    "print('{} Model Summary'.format(model_type))\n",
    "model.summarize(sample_input)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.97)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "num_epochs = 40\n",
    "restore = True\n",
    "checkpoint_tag = '4-24-res{0}-{1}'.format(resnet_style,weights)\n",
    "checkpoint_path = './checkpoints/{0}_checkpoint_{1}.pth.tar'.format(model_type,checkpoint_tag)\n",
    "best_checkpoint_path = './checkpoints/{0}_checkpoint{1}_best.pth.tar'.format(model_type,checkpoint_tag)\n",
    "\n",
    "if restore:\n",
    "    print('Checking to restore...')\n",
    "    if os.path.isfile(checkpoint_path):\n",
    "        print('Restoring checkpoint from {}'.format(checkpoint_path))\n",
    "        state = torch.load(checkpoint_path)\n",
    "        epoch = state['epoch']\n",
    "        model.load_state_dict(state['state_dict'])\n",
    "        optimizer.load_state_dict(state['optimizer'])\n",
    "        scheduler.load_state_dict(state['scheduler'])\n",
    "    else:\n",
    "        print('No checkpoint found at {}'.format(checkpoint_path))\n",
    "        epoch = 0\n",
    "else:\n",
    "    print('Not checking to restore')\n",
    "    epoch = 0\n",
    "\n",
    "best_loss = np.inf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "175it [01:53,  1.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.025727465293993855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.022149322838987205 cumulative_threat_score: 348.3143310546875 val_len: 491 mean_threat_score: 0.7093978229219705\n",
      "best model after 1 epoch saved...\n",
      "model after 1 epoch saved...\n",
      "Epoch 1/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [01:49,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.018870074097301202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.017541053460231867 cumulative_threat_score: 372.8281555175781 val_len: 491 mean_threat_score: 0.7593241456569819\n",
      "best model after 2 epoch saved...\n",
      "model after 2 epoch saved...\n",
      "Epoch 2/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [01:48,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.013742169919733085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.016348334685605315 cumulative_threat_score: 387.1137390136719 val_len: 491 mean_threat_score: 0.7884190203944438\n",
      "best model after 3 epoch saved...\n",
      "model after 3 epoch saved...\n",
      "Epoch 3/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [01:48,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.010811657071969667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.013942611860889038 cumulative_threat_score: 396.41058349609375 val_len: 491 mean_threat_score: 0.8073535305419425\n",
      "best model after 4 epoch saved...\n",
      "model after 4 epoch saved...\n",
      "Epoch 4/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [01:48,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.008639877202587881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.011291452647469438 cumulative_threat_score: 412.43194580078125 val_len: 491 mean_threat_score: 0.8399835963356034\n",
      "best model after 5 epoch saved...\n",
      "model after 5 epoch saved...\n",
      "Epoch 5/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [01:49,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.007388100750356431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.011425864672223807 cumulative_threat_score: 413.3017578125 val_len: 491 mean_threat_score: 0.8417551075610998\n",
      "model after 6 epoch saved...\n",
      "Epoch 6/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175it [01:49,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train running_loss: 0.006844504324709277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "31it [00:15,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val running_loss: 0.010210585706467056 cumulative_threat_score: 421.17572021484375 val_len: 491 mean_threat_score: 0.8577916908652622\n",
      "best model after 7 epoch saved...\n",
      "model after 7 epoch saved...\n",
      "Epoch 7/39\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:34,  1.62it/s]"
     ]
    }
   ],
   "source": [
    "while epoch < num_epochs:\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()  # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        threat_score = 0.0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for i, temp_batch in tqdm(enumerate(dataloaders[phase])):\n",
    "            samples, targets, road_images, extras  = temp_batch\n",
    "            samples = torch.stack(samples).to(device)\n",
    "            road_images = torch.stack(road_images).to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                if model_type == 'ae':\n",
    "                    pred_maps = model(samples)\n",
    "                    loss = criterion(pred_maps, road_images.float())\n",
    "                elif model_type == 'vae':\n",
    "                    pred_maps, mu, logvar = model(samples,phase == 'train')\n",
    "                    loss, CE, KLD = loss_function(pred_maps, road_images, mu, logvar)\n",
    "                \n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                else:\n",
    "                    for pred_map,road_image in zip(pred_maps,road_images):\n",
    "                        ts_road_map = compute_ts_road_map(pred_map > threshold, road_image)\n",
    "                        threat_score += ts_road_map\n",
    "\n",
    "            running_loss += loss.item()#*batch_size\n",
    "\n",
    "            # tensorboardX logging\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar(phase+'_loss', loss.item(), epoch * len(train_set) / batch_size + i)\n",
    "                if model_type == 'vae':\n",
    "                    writer.add_scalar(phase+'_loss_CE', CE.item(), epoch * len(train_set) / batch_size + i)\n",
    "                    writer.add_scalar(phase+'_loss_KLD', KLD.item(), epoch * len(train_set) / batch_size + i)\n",
    "\n",
    "            # statistics\n",
    "        if phase == 'train':\n",
    "            running_loss = running_loss / len(train_set) # per batch, per sample\n",
    "            print(phase, 'running_loss:', running_loss)\n",
    "        else:\n",
    "            running_loss = running_loss / len(val_set)\n",
    "            print(phase,'running_loss:', running_loss, 'cumulative_threat_score:', threat_score.item(), 'val_len:',len(val_set), 'mean_threat_score:',threat_score.item() / len(val_set))#, iou / len(val_set))\n",
    "            writer.add_scalar(phase+'_ts', threat_score.item()/len(val_set), (epoch + 1) * len(train_set) / batch_size)\n",
    "\n",
    "    # Saving best model so far\n",
    "    if running_loss < best_loss:\n",
    "        best_loss = running_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict()\n",
    "            }, best_checkpoint_path)\n",
    "        print('best model after %d epoch saved...' % (epoch+1))\n",
    "\n",
    "    # save model per epoch\n",
    "    torch.save({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict()\n",
    "        }, checkpoint_path)\n",
    "    print('model after %d epoch saved...' % (epoch+1))\n",
    "    epoch += 1\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labeled_scene_index = np.arange(132, 134)\n",
    "# The labeled dataset can only be retrieved by sample.\n",
    "# And all the returned data are tuple of tensors, since bounding boxes may have different size\n",
    "# You can choose whether the loader returns the extra_info. It is optional. You don't have to use it.\n",
    "test_labeled_set = LabeledDataset(image_folder=image_folder,\n",
    "                                  annotation_file=annotation_csv,\n",
    "                                  scene_index=test_labeled_scene_index,\n",
    "                                  transform=transform,\n",
    "                                  extra_info=True\n",
    "                                 )\n",
    "testloader = torch.utils.data.DataLoader(test_labeled_set, batch_size=1, shuffle=True, num_workers=4, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vae\n",
      "Restoring Best checkpoint from ./checkpoints/vae_checkpoint_random_132_p100_best.pth.tar\n",
      "Total Threat Score is: 0.8383897542953491\n"
     ]
    }
   ],
   "source": [
    "print(model_type)\n",
    "print('Restoring Best checkpoint from {}'.format(best_checkpoint_path))\n",
    "state = torch.load(best_checkpoint_path)\n",
    "epoch = state['epoch']\n",
    "model.load_state_dict(state['state_dict'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "threat_score = 0.0\n",
    "total = 0.0\n",
    "display_images = False\n",
    "\n",
    "for i, temp_batch in enumerate(testloader):\n",
    "#     if i == 30:\n",
    "#         break\n",
    "        \n",
    "    total += len(temp_batch[0])\n",
    "    samples, targets, road_images, extra = temp_batch\n",
    "    samples = torch.stack(samples)\n",
    "\n",
    "    if model_type == 'ae':\n",
    "        pred_maps = model(samples)\n",
    "    elif model_type == 'vae':\n",
    "        pred_maps, mu, logvar = model(samples.to(device),is_training=False)\n",
    "    \n",
    "    ts_road_map = compute_ts_road_map(pred_maps[0].to(device) > threshold, road_images[0].to(device))\n",
    "    threat_score += ts_road_map\n",
    "    if display_images:\n",
    "        print('Test Sample: {}'.format(i))\n",
    "        plt.imshow(torchvision.utils.make_grid(samples[0], nrow=3).numpy().transpose(1, 2, 0))\n",
    "            # CAM_FRONT_LEFT, CAM_FRONT, CAM_FRONT_RIGHT, CAM_BACK_LEFT, CAM_BACK, CAM_BACK_RIGHT\n",
    "#     plt.axis('off');\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        fig.suptitle('Road Map Comparison')\n",
    "        ax1.imshow(road_images[0].detach().cpu(), cmap='binary');\n",
    "        ax1.set_title('Original Road Map')\n",
    "        ax2.imshow((pred_maps[0] > threshold).detach().cpu(), cmap='binary');\n",
    "        ax2.set_title('Predicted Road Map')\n",
    "        plt.show()\n",
    "        print('-'*20)\n",
    "    \n",
    "threat_score /= total\n",
    "print('Total samples: {}, Total Threat Score: {}'.format(total,total*threat_score))\n",
    "print('Mean Threat Score is: {}'.format(threat_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Performance on Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Threat Score is: 0.9356419444084167\n"
     ]
    }
   ],
   "source": [
    "phase = 'val'\n",
    "threat_score = 0.0\n",
    "total = 0.0\n",
    "display_images = False\n",
    "\n",
    "for i, temp_batch in enumerate(dataloaders[phase]):\n",
    "#     if i==5:\n",
    "#         break\n",
    "    total += len(temp_batch[0])\n",
    "    samples, targets, road_images, extras  = temp_batch\n",
    "    samples = torch.stack(samples).to(device)\n",
    "    road_images = torch.stack(road_images).to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        if model_type == 'ae':\n",
    "            pred_maps = model(samples)\n",
    "            loss = criterion(pred_maps, road_images.float())\n",
    "        elif model_type == 'vae':\n",
    "            pred_maps, mu, logvar = model(samples,False)\n",
    "            loss, CE, KLD = loss_function(pred_maps, road_images, mu, logvar)\n",
    "\n",
    "        for pred_map,road_image in zip(pred_maps,road_images):\n",
    "            ts_road_map = compute_ts_road_map(pred_map > threshold, road_image)\n",
    "            threat_score += ts_road_map\n",
    "\n",
    "        if display_images:\n",
    "            plt.imshow(torchvision.utils.make_grid(samples[0], nrow=3).numpy().transpose(1, 2, 0))\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "            fig.suptitle('Road Map Comparison')\n",
    "            ax1.imshow(road_image.detach().cpu(), cmap='binary');\n",
    "            ax1.set_title('Original Road Map')\n",
    "            ax2.imshow((pred_map > threshold).detach().cpu(), cmap='binary');\n",
    "            ax2.set_title('Predicted Road Map')\n",
    "            plt.show()\n",
    "            print('-'*20)\n",
    "                \n",
    "threat_score /= total\n",
    "print('Total samples: {}, Total Threat Score: {}'.format(total,total*threat_score))\n",
    "print('Mean Threat Score is: {}'.format(threat_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Performance on Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 2785.0, Total Threat Score: 2664.673095703125\n",
      "Mean Threat Score is: 0.9567946195602417\n"
     ]
    }
   ],
   "source": [
    "phase = 'train'\n",
    "threat_score = 0.0\n",
    "total = 0.0\n",
    "display_images = False\n",
    "\n",
    "for i, temp_batch in enumerate(dataloaders[phase]):\n",
    "    if i==5:\n",
    "        break\n",
    "    total += len(temp_batch[0])\n",
    "    samples, targets, road_images, extras  = temp_batch\n",
    "    samples = torch.stack(samples).to(device)\n",
    "    road_images = torch.stack(road_images).to(device)\n",
    "\n",
    "    with torch.set_grad_enabled(False):\n",
    "        if model_type == 'ae':\n",
    "            pred_maps = model(samples)\n",
    "            loss = criterion(pred_maps, road_images.float())\n",
    "        elif model_type == 'vae':\n",
    "            pred_maps, mu, logvar = model(samples,False)\n",
    "            loss, CE, KLD = loss_function(pred_maps, road_images, mu, logvar)\n",
    "\n",
    "        for pred_map,road_image in zip(pred_maps,road_images):\n",
    "            ts_road_map = compute_ts_road_map(pred_map > threshold, road_image)\n",
    "            threat_score += ts_road_map\n",
    "\n",
    "        if display_images:\n",
    "            plt.imshow(torchvision.utils.make_grid(samples[0].cpu(), nrow=3).numpy().transpose(1, 2, 0))\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "            fig.suptitle('Road Map Comparison')\n",
    "            ax1.imshow(road_image.detach().cpu(), cmap='binary');\n",
    "            ax1.set_title('Original Road Map')\n",
    "            ax2.imshow((pred_map > threshold).detach().cpu(), cmap='binary');\n",
    "            ax2.set_title('Predicted Road Map')\n",
    "            plt.show()\n",
    "            print('-'*20)\n",
    "                \n",
    "threat_score /= total\n",
    "print('Total samples: {}, Total Threat Score: {}'.format(total,total*threat_score))\n",
    "print('Mean Threat Score is: {}'.format(threat_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
