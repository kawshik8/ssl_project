{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:23.078844Z",
     "start_time": "2020-05-07T16:51:21.719746Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import random\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box, compute_ts_road_map\n",
    "from modelzoo import *\n",
    "from simclr_transforms import *\n",
    "import contrastive_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:23.135431Z",
     "start_time": "2020-05-07T16:51:23.082974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device - cuda:0\n",
      "CUDA Device Count - 1\n",
      "CUDA Device Name - Tesla P40\n",
      "CUDA Device Memory - 22.38 GB\n"
     ]
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "seed = 8964\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Current Device - %s\" % device)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Count - %s\" % torch.cuda.device_count())\n",
    "    print(\"CUDA Device Name - %s\" % torch.cuda.get_device_name())\n",
    "    print(\"CUDA Device Memory - %0.2f GB\"%(float(torch.cuda.get_device_properties(0).total_memory)/1024**3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simclr Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:23.847016Z",
     "start_time": "2020-05-07T16:51:23.138257Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: simclr_model\n",
      "Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "----\n",
      "     Class: encoder\n",
      "     resnet_style: 18, pretrained: False\n",
      "     Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "     Output Size:torch.Size([3, 512, 8, 8])\n",
      "----\n",
      "Hidden state shape: torch.Size([3, 512, 8, 8])\n",
      "Pooled Hidden state shape: torch.Size([3, 512, 1, 1])\n",
      "Reshaped Hidden state shape: torch.Size([3, 512])\n",
      "Output shape:torch.Size([3, 16])\n"
     ]
    }
   ],
   "source": [
    "model = simclr_model()\n",
    "inp = torch.rand([3,3,256,306])\n",
    "model.summarize(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting data details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:30.439133Z",
     "start_time": "2020-05-07T16:51:30.418701Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform1\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "\n",
    "# transform2\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomGrayscale(p=0.5),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     get_color_distortion(s=0.5),\n",
    "#     RandomGaussianBluring(kernel_size=5),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "\n",
    "# transform3\n",
    "eval_transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    get_color_distortion(s=0.5),\n",
    "    RandomGaussianBluring(kernel_size=5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "image_folder = '../data'\n",
    "annotation_csv = '../data/annotation.csv'\n",
    "\n",
    "unlabeled_scene_index = np.arange(106)\n",
    "\n",
    "start_index = 0\n",
    "end_index = 106\n",
    "\n",
    "# V1 = (21,5,2)\n",
    "# V2 = (26,1,1)\n",
    "V3 = (90,16,0)\n",
    "\n",
    "n_train_samples , n_val_samples , n_test_samples = V3\n",
    "\n",
    "assert n_train_samples + n_val_samples + n_test_samples == 106 #No of labeled samples\n",
    "\n",
    "scene_buffer_length = 128\n",
    "\n",
    "\n",
    "train_unlabeled_scene_index = np.arange(start_index, start_index+n_train_samples)\n",
    "val_unlabeled_scene_index = np.arange(start_index+n_train_samples,start_index+n_train_samples+n_val_samples)\n",
    "test_unlabeled_scene_index = np.arange(start_index+n_train_samples+n_val_samples, end_index)\n",
    "\n",
    "train_unlabeled_set = UnlabeledDataset(image_folder=image_folder, scene_index=train_unlabeled_scene_index, first_dim='image', transform=train_transform, scene_buffer_length=scene_buffer_length)\n",
    "\n",
    "\n",
    "val_unlabeled_set = UnlabeledDataset(image_folder=image_folder, scene_index=val_unlabeled_scene_index, first_dim='image', transform=train_transform, scene_buffer_length=scene_buffer_length)\n",
    "\n",
    "if n_test_samples != 0:\n",
    "\n",
    "    test_unlabeled_set = UnlabeledDataset(image_folder=image_folder, scene_index=test_unlabeled_scene_index, first_dim='image', transform=train_transform, scene_buffer_length=scene_buffer_length)\n",
    "\n",
    "else:\n",
    "    \n",
    "    test_unlabeled_set = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:30.620564Z",
     "start_time": "2020-05-07T16:51:30.617313Z"
    }
   },
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "# import contrastive_loss\n",
    "# reload(contrastive_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:30.864255Z",
     "start_time": "2020-05-07T16:51:30.843479Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_experiment(model_tag, batch_size = 64, resnet_style = '18', weights ='random', model_type ='simclr', checkpoint_folder = '/scratch/sc6957/dlproject/checkpoints/'):\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_unlabeled_set, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "    val_loader = torch.utils.data.DataLoader(val_unlabeled_set, batch_size=batch_size, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "    if test_unlabeled_set is not None:\n",
    "        test_loader = torch.utils.data.DataLoader(test_unlabeled_set, batch_size=1, shuffle=True, num_workers=4, collate_fn=collate_fn)\n",
    "    else:\n",
    "        test_loader = None\n",
    "    \n",
    "    dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader}\n",
    "\n",
    "    if weights == 'random':\n",
    "        pretrained = False\n",
    "    elif weights == 'imagenet':\n",
    "        pretrained = True\n",
    "\n",
    "    print('Model Type: {0}'.format(model_type))\n",
    "\n",
    "    model = simclr_model(resnet_style=resnet_style, pretrained=pretrained)\n",
    "    \n",
    "    sample_input = torch.rand([3,3,256,306])\n",
    "        \n",
    "    print('{} Model Summary'.format(model_type))\n",
    "    model.summarize(sample_input)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.0001)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.97)\n",
    "    \n",
    "    criterion = contrastive_loss.contrastive_loss(tau=0.1, normalize=True)\n",
    "\n",
    "    today = datetime.now().date()\n",
    "    \n",
    "    checkpoint_tag = '{0}-{1}{2}'.format(today.day,today.month, model_tag)\n",
    "    checkpoint_path = checkpoint_folder + 'checkpoint_{0}.pth.tar'.format(checkpoint_tag)\n",
    "    best_checkpoint_path = checkpoint_folder + 'checkpoint_{0}_best.pth.tar'.format(checkpoint_tag)\n",
    "\n",
    "    return model, optimizer, scheduler, criterion, dataloaders, checkpoint_path, best_checkpoint_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:31.754351Z",
     "start_time": "2020-05-07T16:51:31.715475Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, model_type, model_tag, optimizer, scheduler, criterion, restore, threshold, dataloaders, checkpoint_path, best_checkpoint_path, tensorboard_log_dir):\n",
    "\n",
    "    if restore:\n",
    "        print('Checking to restore...')\n",
    "        if os.path.isfile(checkpoint_path):\n",
    "            print('Restoring checkpoint from {}'.format(checkpoint_path))\n",
    "            state = torch.load(checkpoint_path)\n",
    "            epoch = state['epoch']\n",
    "            best_loss = state['best_loss']\n",
    "            best_ts = state['best_ts']\n",
    "#             new_state_dict = OrderedDict((re.sub('encoder','encoder_after_resnet',k) if 'mmd_encoder.' in k else k, v) for k, v in state['state_dict'].items())\n",
    "#             model.load_state_dict(new_state_dict)\n",
    "            model.load_state_dict(state['state_dict'])\n",
    "            optimizer.load_state_dict(state['optimizer'])\n",
    "            scheduler.load_state_dict(state['scheduler'])\n",
    "        else:\n",
    "            print('No checkpoint found at {}'.format(checkpoint_path))\n",
    "            epoch = 0\n",
    "            best_loss = np.inf\n",
    "            best_ts = 0\n",
    "    else:\n",
    "        print('Not checking to restore')\n",
    "        epoch = 0\n",
    "        best_loss = np.inf\n",
    "        best_ts = 0\n",
    "            \n",
    "    writer = SummaryWriter(log_dir=tensorboard_log_dir, comment=model_tag)\n",
    "\n",
    "    while epoch < num_epochs:\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_acc = 0.0\n",
    "            \n",
    "            # Iterate over data.\n",
    "            for i, temp_batch in tqdm(enumerate(dataloaders[phase])):\n",
    "                x_i, x_j  = temp_batch\n",
    "                x_i = torch.stack(x_i).to(device)\n",
    "                x_j = torch.stack(x_j).to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    if model_type == 'simclr':\n",
    "                        loss, batch_acc = criterion(model(x_i),model(x_j))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    else:\n",
    "                        pass\n",
    "\n",
    "                running_loss += loss.item()#*batch_size\n",
    "                running_acc += batch_acc.item()\n",
    "                # tensorboard logging\n",
    "                if phase == 'train':\n",
    "                    writer.add_scalar(phase+'_loss', loss.item(), epoch * len(train_unlabeled_set) / dataloaders[phase].batch_size + i)\n",
    "                    writer.add_scalar(phase+'_acc', batch_acc.item(), epoch * len(train_unlabeled_set) / dataloaders[phase].batch_size + i)\n",
    "                    if model_type == 'simclr':\n",
    "                        pass\n",
    "                # statistics\n",
    "            mean_batch_loss = running_loss/len(dataloaders[phase])\n",
    "            mean_batch_acc = running_acc/len(dataloaders[phase])\n",
    "            \n",
    "            print(phase, 'mean_batch_loss:', round(mean_batch_loss,4))\n",
    "            print(phase, 'total_loss:', round(running_loss,4))\n",
    "            print(phase, 'mean_batch_acc:', round(mean_batch_acc,4))\n",
    "            writer.add_scalar(phase+'_mean_batch_loss', mean_batch_loss, epoch)\n",
    "            writer.add_scalar(phase+'_mean_batch_acc', mean_batch_acc, epoch)\n",
    "\n",
    "\n",
    "        # Saving best loss model so far\n",
    "        if running_loss < best_loss:\n",
    "            best_loss = running_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'best_loss': best_loss,\n",
    "                'best_ts': best_ts\n",
    "                }, best_checkpoint_path)\n",
    "            print('best_loss model after %d epoch saved...' % (epoch+1))\n",
    "            \n",
    "        # Saving best ts model so far\n",
    "        if mean_batch_acc > best_ts:\n",
    "            best_ts = mean_batch_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'scheduler': scheduler.state_dict(),\n",
    "                'best_loss': best_loss,\n",
    "                'best_ts': best_ts\n",
    "                }, best_checkpoint_path)\n",
    "            print('best_ts model after %d epoch saved...' % (epoch+1))\n",
    "\n",
    "        # save model per epoch\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'scheduler': scheduler.state_dict(),\n",
    "            'best_loss': best_loss,\n",
    "            'best_ts': best_ts\n",
    "            }, checkpoint_path)\n",
    "        print('model after %d epoch saved...' % (epoch+1))\n",
    "        epoch += 1\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T16:51:35.809209Z",
     "start_time": "2020-05-07T16:51:32.990197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_tag:_Batch:128_Model:simclr18random_dataV3_scenewise_16dim_acc\n",
      "Model Type: simclr\n",
      "simclr Model Summary\n",
      "Class: simclr_model\n",
      "Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "----\n",
      "     Class: encoder\n",
      "     resnet_style: 18, pretrained: False\n",
      "     Passed Input Size:torch.Size([3, 3, 256, 306])\n",
      "     Output Size:torch.Size([3, 512, 8, 8])\n",
      "----\n",
      "Hidden state shape: torch.Size([3, 512, 8, 8])\n",
      "Pooled Hidden state shape: torch.Size([3, 512, 1, 1])\n",
      "Reshaped Hidden state shape: torch.Size([3, 512])\n",
      "Output shape:torch.Size([3, 16])\n"
     ]
    }
   ],
   "source": [
    "checkpoint_folder = '/scratch/sc6957/dlproject/checkpoints/'\n",
    "tensorboard_log_dir = '/scratch/sc6957/dlproject/tb_logs'\n",
    "\n",
    "batch_size = scene_buffer_length\n",
    "resnet_style = '18'\n",
    "weights = 'random'\n",
    "model_type ='simclr'\n",
    "num_epochs = 20\n",
    "threshold = 0.5\n",
    "restore = False # Restore from checkpoint, if checkpoint exists\n",
    "\n",
    "model_tag = '_Batch:{}_Model:{}'.format(batch_size,model_type+resnet_style+weights)\n",
    "if test_unlabeled_set is None:\n",
    "    model_tag += '_dataV3'\n",
    "\n",
    "model_tag += '_scenewise_16dim_acc'\n",
    "print('model_tag:{}'.format(model_tag))\n",
    "    \n",
    "parameters = prepare_experiment(model_tag = model_tag, batch_size = batch_size, resnet_style = resnet_style, weights = weights, model_type = model_type, checkpoint_folder = checkpoint_folder)\n",
    "\n",
    "model, optimizer, scheduler, criterion, dataloaders, checkpoint_path, best_checkpoint_path = parameters   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-07T16:51:38.422Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not checking to restore\n",
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(num_epochs, model, model_type, model_tag, optimizer, scheduler,  criterion, restore, threshold, dataloaders, checkpoint_path, best_checkpoint_path, tensorboard_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T16:31:10.764728Z",
     "start_time": "2020-05-04T16:31:10.746848Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, model_type, model_path, dataloaders, phase, display_images = False, n_batch_to_display = 3, threshold = 0.5):\n",
    "    \n",
    "    assert phase != 'unlabeled'\n",
    "    \n",
    "    print('Estimating performance on {} set'.format(phase))\n",
    "    print('Restoring Best checkpoint from {}'.format(model_path))\n",
    "    state = torch.load(model_path)\n",
    "    epoch = state['epoch']\n",
    "#     new_state_dict = OrderedDict((re.sub('encoder','encoder_after_resnet',k) if 'mmd_encoder.' in k else k, v) for k, v in state['state_dict'].items())\n",
    "#     model.load_state_dict(new_state_dict)\n",
    "    model.load_state_dict(state['state_dict'])\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    total = 0.0\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for i, temp_batch in tqdm(enumerate(dataloaders[phase])):\n",
    "        if display_images and i == n_batch_to_display:\n",
    "            break\n",
    "        total += len(temp_batch[0])\n",
    "        x_i, x_j  = temp_batch\n",
    "        x_i = torch.stack(x_i).to(device)\n",
    "        x_j = torch.stack(x_j).to(device)\n",
    "        if model_type == 'simclr':\n",
    "            loss = criterion(model(x_i),model(x_j))\n",
    "        \n",
    "        total_loss += loss.item() \n",
    "\n",
    "\n",
    "    total_loss /= len(dataloaders[phase])\n",
    "    print('Total samples: {}, Total Threat Score: {}'.format(total,total*total_loss))\n",
    "    print('Mean Loss is: {}'.format(total_loss))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Performance on Val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T16:07:38.097804Z",
     "start_time": "2020-05-06T16:07:38.000707Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 19.265180371701717, 99.83597883597884)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_checkpoint_path = '/scratch/sc6957/dlproject/checkpoints/checkpoint_6-5_Batch:64_Model:simclr18random_dataV3_scenewise_64dim_acc.pth.tar'\n",
    "state = torch.load(best_checkpoint_path)\n",
    "state['epoch'],state['best_loss'],state['best_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T16:32:13.666796Z",
     "start_time": "2020-05-04T16:31:15.684855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating performance on val set\n",
      "Restoring Best checkpoint from /scratch/sc6957/dlproject/checkpoints/checkpoint_4-5_Batch:64_Model:simclr18random_dataV3transforms3.pth.tar\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-531e0e82b08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# evaluate(model, model_type, best_checkpoint_path, dataloaders,  'test', display_images = True , n_batch_to_display = 10, threshold = 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_checkpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_batch_to_display\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# evaluate(model, model_type, best_checkpoint_path, dataloaders,  'train', display_images = True , n_batch_to_display = 1, threshold = 0.5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b687d70308c4>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, model_type, model_path, dataloaders, phase, display_images, n_batch_to_display, threshold)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdisplay_images\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn_batch_to_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0manswer_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mdeliver_challenge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mdeliver_challenge\u001b[0;34m(connection, authkey)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n\u001b[1;32m    726\u001b[0m     \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMESSAGE_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m     \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHALLENGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m     \u001b[0mdigest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhmac\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'md5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdigest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# reject large message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend_bytes\u001b[0;34m(self, buf, offset, size)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"buffer length < offset + size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send_bytes\u001b[0;34m(self, buf)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# Also note we want to avoid sending a 0-length buffer separately,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# to avoid \"broken pipe\" errors if the other end closed the pipe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/sc6957/miniconda3/envs/capstone/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_send\u001b[0;34m(self, buf, write)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mremaining\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# evaluate(model, model_type, best_checkpoint_path, dataloaders,  'test', display_images = True , n_batch_to_display = 10, threshold = 0.5)\n",
    "evaluate(model, model_type, best_checkpoint_path, dataloaders,  'val', display_images = False , n_batch_to_display = 1, threshold = 0.5)\n",
    "# evaluate(model, model_type, best_checkpoint_path, dataloaders,  'train', display_images = True , n_batch_to_display = 1, threshold = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
