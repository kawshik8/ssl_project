{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle and learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train encoder to predict if 3 frames are in correct temporal order or not.  \n",
    "Paper: https://arxiv.org/abs/1603.08561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('/scratch/mz2476/DL/project/')\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "from ssl_project.data_loaders import plot_utils\n",
    "\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from ssl_project.data_loaders.data_helper import UnlabeledDataset, LabeledDataset\n",
    "from ssl_project.data_loaders.helper import collate_fn, draw_box\n",
    "from ssl_project import constants\n",
    "\n",
    "from ssl_project.preprocessing import top_down_segmentation\n",
    "\n",
    "\n",
    "from ssl_project.utils import to_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ssl_project.constants import *\n",
    "from ssl_project.paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssl_project.ssl_ideas.preprocessing import TripleDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data:\n",
    "triples of photos, can be separate datasets for each camera view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for idx in range(5):\n",
    "#     img = imageio.imread(f\"../data/scene_30/sample_{idx}/CAM_FRONT.jpeg\")\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_dataset = TripleDataset(cam_names=[\"CAM_FRONT\"], scene_ids=UNLABELED_SCENE_INDEX)\n",
    "# len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# positive_counter = 0 \n",
    "# for idx in range(0, 1000, 10):\n",
    "#     if positive_counter > 10: \n",
    "#         break \n",
    "#     images_o3hw, label = train_dataset[idx]\n",
    "    \n",
    "#     if label == 1:\n",
    "#         positive_counter += 1\n",
    "#         plot_utils.plot_photos(images_o3hw)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# positive_counter = 0 # negative ...\n",
    "# for idx in range(0, 1000, 10):\n",
    "#     if positive_counter > 10: \n",
    "#         break \n",
    "#     images_o3hw, label = train_dataset[idx]\n",
    "    \n",
    "#     if label == 0:\n",
    "#         positive_counter += 1\n",
    "#         plot_utils.plot_photos(images_o3hw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from ssl_project.road_layout_prediction.modelzoo import encoder\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "# matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "seed = 8964\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed);\n",
    "\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = torchvision.models.resnet18(pretrained=True)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ssl_project.constants import LABELED_SCENE_INDEX, UNLABELED_SCENE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idces = UNLABELED_SCENE_INDEX\n",
    "val_idces = LABELED_SCENE_INDEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleAndLearnNet(nn.Module):\n",
    "    def __init__(self, resnet_style='18', pretrained=False):\n",
    "        super().__init__()\n",
    "        # compute hparams\n",
    "        self.hparams = {\n",
    "            key : value for key, value in locals().items()\n",
    "            if not (key == \"self\" or key.startswith(\"__\"))\n",
    "        }\n",
    "        \n",
    "        self.resnet_encoder = encoder(resnet_style='18', pretrained=False)\n",
    "        OUT_ENC_CHANNELS = 512 # might change in the future\n",
    "        # output 512 x 8 x 8\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(3 * OUT_ENC_CHANNELS, OUT_ENC_CHANNELS, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(OUT_ENC_CHANNELS, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "        )\n",
    "        self.clf = nn.Linear(in_features=OUT_ENC_CHANNELS, out_features=2, bias=True)\n",
    "        \n",
    "    def forward(self, images_bo3hw):\n",
    "        # c = 512, l = 8\n",
    "        image_1_bcll = self.resnet_encoder(images_bo3hw[:, 0])\n",
    "        image_2_bcll = self.resnet_encoder(images_bo3hw[:, 1])\n",
    "        image_3_bcll = self.resnet_encoder(images_bo3hw[:, 2])\n",
    "        out_bm11 = self.decoder(torch.cat((image_1_bcll, image_2_bcll, image_3_bcll), dim=1))\n",
    "#         assert out_bm11.shape[-2:] == (1, 1)\n",
    "        out_b2 = self.clf(out_bm11.view(out_bm11.shape[:2]))\n",
    "        return out_b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShuffleAndLearnModel(pl.LightningModule):\n",
    "    def __init__(self, model, hparams):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.cam_names = hparams[\"cam_names\"]\n",
    "        self.hparams = hparams\n",
    "        self.hparams[\"cam_names\"] = \"__\".join(self.hparams[\"cam_names\"])\n",
    "#         assert len(set(hparams.keys()) & set(self.model.hparams.keys())) == 0\n",
    "        self.hparams.update({f\"model_{k}\" : v for k, v in self.model.hparams.items()})\n",
    "        \n",
    "        self.criterion = nn.BCEWithLogitsLoss(reduction=\"sum\")\n",
    "        self.threshold = 0.5\n",
    "        self.num_workers = 4\n",
    "        \n",
    "#     def forward(self, images_bo3hw, cam_name):\n",
    "#         resnet_encoder = self.cam_name_to_encoder[cam_name]\n",
    "#         image_1_bcll = resnet_encoder(image_bo3hw[:, 0])\n",
    "#         image_2_bcll = resnet_encoder(image_bo3hw[:, 1])\n",
    "#         image_3_bcll = resnet_encoder(image_bo3hw[:, 2])\n",
    "        \n",
    "#         out_b2 = self.classifier(torch.cat((image_1_bcll, image_2_bcll, image_3_bcll), dim=1))\n",
    "#         return out_b2\n",
    "    \n",
    "        \n",
    "    def forward(self, images_bo3hw):\n",
    "        return self.model(images_bo3hw)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images_bo3hw, labels_b = batch\n",
    "        out_b = self.forward(images_bo3hw)[:, 1]\n",
    "        loss = self.criterion(out_b, labels_b.type_as(out_b))\n",
    "        tensorboard_logs = {'train_loss': loss}\n",
    "        return {\n",
    "            'loss': loss, \n",
    "            'log': tensorboard_logs\n",
    "        }\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            TripleDataset(cam_names=self.cam_names, scene_ids=train_idces), \n",
    "            num_workers=self.num_workers, \n",
    "            batch_size=32,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            TripleDataset(cam_names=self.cam_names, scene_ids=val_idces), \n",
    "            num_workers=self.num_workers, \n",
    "            batch_size=32, \n",
    "            shuffle=False, \n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def on_train_start(self):\n",
    "        self.logger.log_hyperparams_metrics(\n",
    "            self.hparams, {'val_loss': 1, 'val_acc': 0})\n",
    "\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images_bo3hw, labels_b = batch\n",
    "        out_b = self.forward(images_bo3hw)[:, 1]\n",
    "        return {\n",
    "            'val_loss': self.criterion(out_b, labels_b.type_as(out_b)),\n",
    "            'val_acc' : ((out_b > self.threshold).long() == labels_b).float().sum(),\n",
    "        }\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = (torch.stack([x['val_loss'] for x in outputs]).sum() / self.val_size).item()\n",
    "        avg_acc = (torch.stack([x['val_acc'] for x in outputs]).sum() / self.val_size).item()\n",
    "\n",
    "        tensorboard_logs = {'val_loss': avg_loss, 'val_acc' : avg_acc,}\n",
    "                \n",
    "        return {\n",
    "            'val_loss': avg_loss, \n",
    "            'val_acc' : avg_acc,\n",
    "            'log': tensorboard_logs\n",
    "        }\n",
    " \n",
    "    @property\n",
    "    def val_size(self):\n",
    "        return len(self.val_dataloader().dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# trainer.logger.log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from logger_hparams import HyperparamsSummaryTensorBoardLogger\n",
    "\n",
    "logger = HyperparamsSummaryTensorBoardLogger(\"lightning_logs\", name=\"cam_front_full\", version=\"02\")\n",
    "\n",
    "\n",
    "net = ShuffleAndLearnNet()\n",
    "model_with_data = ShuffleAndLearnModel(net, {\"cam_names\" : [\"CAM_FRONT\"]})\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, \n",
    "#                      auto_lr_find=True, \n",
    "                     show_progress_bar=True,\n",
    "#                      train_percent_check=0.02,\n",
    "#                      val_percent_check=0.05,\n",
    "                     logger=logger,\n",
    "            )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<logger_hparams.HyperparamsSummaryTensorBoardLogger at 0x2ac74a8ac7c0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.logger\n",
    "\n",
    "model_with_data.logger = trainer.logger\n",
    "\n",
    "trainer.logger\n",
    "\n",
    "model_with_data.logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:Set SLURM handle signals.\n",
      "INFO:lightning:\n",
      "   | Name                                                 | Type               | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | model                                                | ShuffleAndLearnNet | 18 M  \n",
      "1  | model.resnet_encoder                                 | encoder            | 11 M  \n",
      "2  | model.resnet_encoder.resnet_encoder                  | Sequential         | 11 M  \n",
      "3  | model.resnet_encoder.resnet_encoder.0                | Conv2d             | 9 K   \n",
      "4  | model.resnet_encoder.resnet_encoder.1                | BatchNorm2d        | 128   \n",
      "5  | model.resnet_encoder.resnet_encoder.2                | ReLU               | 0     \n",
      "6  | model.resnet_encoder.resnet_encoder.3                | MaxPool2d          | 0     \n",
      "7  | model.resnet_encoder.resnet_encoder.4                | Sequential         | 147 K \n",
      "8  | model.resnet_encoder.resnet_encoder.4.0              | BasicBlock         | 73 K  \n",
      "9  | model.resnet_encoder.resnet_encoder.4.0.conv1        | Conv2d             | 36 K  \n",
      "10 | model.resnet_encoder.resnet_encoder.4.0.bn1          | BatchNorm2d        | 128   \n",
      "11 | model.resnet_encoder.resnet_encoder.4.0.relu         | ReLU               | 0     \n",
      "12 | model.resnet_encoder.resnet_encoder.4.0.conv2        | Conv2d             | 36 K  \n",
      "13 | model.resnet_encoder.resnet_encoder.4.0.bn2          | BatchNorm2d        | 128   \n",
      "14 | model.resnet_encoder.resnet_encoder.4.1              | BasicBlock         | 73 K  \n",
      "15 | model.resnet_encoder.resnet_encoder.4.1.conv1        | Conv2d             | 36 K  \n",
      "16 | model.resnet_encoder.resnet_encoder.4.1.bn1          | BatchNorm2d        | 128   \n",
      "17 | model.resnet_encoder.resnet_encoder.4.1.relu         | ReLU               | 0     \n",
      "18 | model.resnet_encoder.resnet_encoder.4.1.conv2        | Conv2d             | 36 K  \n",
      "19 | model.resnet_encoder.resnet_encoder.4.1.bn2          | BatchNorm2d        | 128   \n",
      "20 | model.resnet_encoder.resnet_encoder.5                | Sequential         | 525 K \n",
      "21 | model.resnet_encoder.resnet_encoder.5.0              | BasicBlock         | 230 K \n",
      "22 | model.resnet_encoder.resnet_encoder.5.0.conv1        | Conv2d             | 73 K  \n",
      "23 | model.resnet_encoder.resnet_encoder.5.0.bn1          | BatchNorm2d        | 256   \n",
      "24 | model.resnet_encoder.resnet_encoder.5.0.relu         | ReLU               | 0     \n",
      "25 | model.resnet_encoder.resnet_encoder.5.0.conv2        | Conv2d             | 147 K \n",
      "26 | model.resnet_encoder.resnet_encoder.5.0.bn2          | BatchNorm2d        | 256   \n",
      "27 | model.resnet_encoder.resnet_encoder.5.0.downsample   | Sequential         | 8 K   \n",
      "28 | model.resnet_encoder.resnet_encoder.5.0.downsample.0 | Conv2d             | 8 K   \n",
      "29 | model.resnet_encoder.resnet_encoder.5.0.downsample.1 | BatchNorm2d        | 256   \n",
      "30 | model.resnet_encoder.resnet_encoder.5.1              | BasicBlock         | 295 K \n",
      "31 | model.resnet_encoder.resnet_encoder.5.1.conv1        | Conv2d             | 147 K \n",
      "32 | model.resnet_encoder.resnet_encoder.5.1.bn1          | BatchNorm2d        | 256   \n",
      "33 | model.resnet_encoder.resnet_encoder.5.1.relu         | ReLU               | 0     \n",
      "34 | model.resnet_encoder.resnet_encoder.5.1.conv2        | Conv2d             | 147 K \n",
      "35 | model.resnet_encoder.resnet_encoder.5.1.bn2          | BatchNorm2d        | 256   \n",
      "36 | model.resnet_encoder.resnet_encoder.6                | Sequential         | 2 M   \n",
      "37 | model.resnet_encoder.resnet_encoder.6.0              | BasicBlock         | 919 K \n",
      "38 | model.resnet_encoder.resnet_encoder.6.0.conv1        | Conv2d             | 294 K \n",
      "39 | model.resnet_encoder.resnet_encoder.6.0.bn1          | BatchNorm2d        | 512   \n",
      "40 | model.resnet_encoder.resnet_encoder.6.0.relu         | ReLU               | 0     \n",
      "41 | model.resnet_encoder.resnet_encoder.6.0.conv2        | Conv2d             | 589 K \n",
      "42 | model.resnet_encoder.resnet_encoder.6.0.bn2          | BatchNorm2d        | 512   \n",
      "43 | model.resnet_encoder.resnet_encoder.6.0.downsample   | Sequential         | 33 K  \n",
      "44 | model.resnet_encoder.resnet_encoder.6.0.downsample.0 | Conv2d             | 32 K  \n",
      "45 | model.resnet_encoder.resnet_encoder.6.0.downsample.1 | BatchNorm2d        | 512   \n",
      "46 | model.resnet_encoder.resnet_encoder.6.1              | BasicBlock         | 1 M   \n",
      "47 | model.resnet_encoder.resnet_encoder.6.1.conv1        | Conv2d             | 589 K \n",
      "48 | model.resnet_encoder.resnet_encoder.6.1.bn1          | BatchNorm2d        | 512   \n",
      "49 | model.resnet_encoder.resnet_encoder.6.1.relu         | ReLU               | 0     \n",
      "50 | model.resnet_encoder.resnet_encoder.6.1.conv2        | Conv2d             | 589 K \n",
      "51 | model.resnet_encoder.resnet_encoder.6.1.bn2          | BatchNorm2d        | 512   \n",
      "52 | model.resnet_encoder.resnet_encoder.7                | Sequential         | 8 M   \n",
      "53 | model.resnet_encoder.resnet_encoder.7.0              | BasicBlock         | 3 M   \n",
      "54 | model.resnet_encoder.resnet_encoder.7.0.conv1        | Conv2d             | 1 M   \n",
      "55 | model.resnet_encoder.resnet_encoder.7.0.bn1          | BatchNorm2d        | 1 K   \n",
      "56 | model.resnet_encoder.resnet_encoder.7.0.relu         | ReLU               | 0     \n",
      "57 | model.resnet_encoder.resnet_encoder.7.0.conv2        | Conv2d             | 2 M   \n",
      "58 | model.resnet_encoder.resnet_encoder.7.0.bn2          | BatchNorm2d        | 1 K   \n",
      "59 | model.resnet_encoder.resnet_encoder.7.0.downsample   | Sequential         | 132 K \n",
      "60 | model.resnet_encoder.resnet_encoder.7.0.downsample.0 | Conv2d             | 131 K \n",
      "61 | model.resnet_encoder.resnet_encoder.7.0.downsample.1 | BatchNorm2d        | 1 K   \n",
      "62 | model.resnet_encoder.resnet_encoder.7.1              | BasicBlock         | 4 M   \n",
      "63 | model.resnet_encoder.resnet_encoder.7.1.conv1        | Conv2d             | 2 M   \n",
      "64 | model.resnet_encoder.resnet_encoder.7.1.bn1          | BatchNorm2d        | 1 K   \n",
      "65 | model.resnet_encoder.resnet_encoder.7.1.relu         | ReLU               | 0     \n",
      "66 | model.resnet_encoder.resnet_encoder.7.1.conv2        | Conv2d             | 2 M   \n",
      "67 | model.resnet_encoder.resnet_encoder.7.1.bn2          | BatchNorm2d        | 1 K   \n",
      "68 | model.resnet_encoder.resnet_encoder.8                | AdaptiveAvgPool2d  | 0     \n",
      "69 | model.decoder                                        | Sequential         | 7 M   \n",
      "70 | model.decoder.0                                      | Conv2d             | 7 M   \n",
      "71 | model.decoder.1                                      | BatchNorm2d        | 1 K   \n",
      "72 | model.decoder.2                                      | ReLU               | 0     \n",
      "73 | model.decoder.3                                      | AdaptiveAvgPool2d  | 0     \n",
      "74 | model.clf                                            | Linear             | 1 K   \n",
      "75 | criterion                                            | BCEWithLogitsLoss  | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea53bc8aa383412987d25b636a188a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d19e19e2685452b9d18cc01ea64cb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ad420ed8fa40889879ecc46967c700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model_with_data, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'asbsadf': 234,\n",
       " 'model_a': 2,\n",
       " 'model_resnet_style': '18',\n",
       " 'model_pretrained': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ShuffleAndLearnNet()\n",
    "model_with_data = ShuffleAndLearnModel(net)\n",
    "trainer = pl.Trainer(gpus=1)    \n",
    "trainer.fit(model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_data.hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(gpus=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning:GPU available: True, used: True\n",
      "INFO:lightning:CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO:lightning:Set SLURM handle signals.\n",
      "INFO:lightning:\n",
      "   | Name                                           | Type              | Params\n",
      "---------------------------------------------------------------------------------\n",
      "0  | resnet_encoder                                 | encoder           | 11 M  \n",
      "1  | resnet_encoder.resnet_encoder                  | Sequential        | 11 M  \n",
      "2  | resnet_encoder.resnet_encoder.0                | Conv2d            | 9 K   \n",
      "3  | resnet_encoder.resnet_encoder.1                | BatchNorm2d       | 128   \n",
      "4  | resnet_encoder.resnet_encoder.2                | ReLU              | 0     \n",
      "5  | resnet_encoder.resnet_encoder.3                | MaxPool2d         | 0     \n",
      "6  | resnet_encoder.resnet_encoder.4                | Sequential        | 147 K \n",
      "7  | resnet_encoder.resnet_encoder.4.0              | BasicBlock        | 73 K  \n",
      "8  | resnet_encoder.resnet_encoder.4.0.conv1        | Conv2d            | 36 K  \n",
      "9  | resnet_encoder.resnet_encoder.4.0.bn1          | BatchNorm2d       | 128   \n",
      "10 | resnet_encoder.resnet_encoder.4.0.relu         | ReLU              | 0     \n",
      "11 | resnet_encoder.resnet_encoder.4.0.conv2        | Conv2d            | 36 K  \n",
      "12 | resnet_encoder.resnet_encoder.4.0.bn2          | BatchNorm2d       | 128   \n",
      "13 | resnet_encoder.resnet_encoder.4.1              | BasicBlock        | 73 K  \n",
      "14 | resnet_encoder.resnet_encoder.4.1.conv1        | Conv2d            | 36 K  \n",
      "15 | resnet_encoder.resnet_encoder.4.1.bn1          | BatchNorm2d       | 128   \n",
      "16 | resnet_encoder.resnet_encoder.4.1.relu         | ReLU              | 0     \n",
      "17 | resnet_encoder.resnet_encoder.4.1.conv2        | Conv2d            | 36 K  \n",
      "18 | resnet_encoder.resnet_encoder.4.1.bn2          | BatchNorm2d       | 128   \n",
      "19 | resnet_encoder.resnet_encoder.5                | Sequential        | 525 K \n",
      "20 | resnet_encoder.resnet_encoder.5.0              | BasicBlock        | 230 K \n",
      "21 | resnet_encoder.resnet_encoder.5.0.conv1        | Conv2d            | 73 K  \n",
      "22 | resnet_encoder.resnet_encoder.5.0.bn1          | BatchNorm2d       | 256   \n",
      "23 | resnet_encoder.resnet_encoder.5.0.relu         | ReLU              | 0     \n",
      "24 | resnet_encoder.resnet_encoder.5.0.conv2        | Conv2d            | 147 K \n",
      "25 | resnet_encoder.resnet_encoder.5.0.bn2          | BatchNorm2d       | 256   \n",
      "26 | resnet_encoder.resnet_encoder.5.0.downsample   | Sequential        | 8 K   \n",
      "27 | resnet_encoder.resnet_encoder.5.0.downsample.0 | Conv2d            | 8 K   \n",
      "28 | resnet_encoder.resnet_encoder.5.0.downsample.1 | BatchNorm2d       | 256   \n",
      "29 | resnet_encoder.resnet_encoder.5.1              | BasicBlock        | 295 K \n",
      "30 | resnet_encoder.resnet_encoder.5.1.conv1        | Conv2d            | 147 K \n",
      "31 | resnet_encoder.resnet_encoder.5.1.bn1          | BatchNorm2d       | 256   \n",
      "32 | resnet_encoder.resnet_encoder.5.1.relu         | ReLU              | 0     \n",
      "33 | resnet_encoder.resnet_encoder.5.1.conv2        | Conv2d            | 147 K \n",
      "34 | resnet_encoder.resnet_encoder.5.1.bn2          | BatchNorm2d       | 256   \n",
      "35 | resnet_encoder.resnet_encoder.6                | Sequential        | 2 M   \n",
      "36 | resnet_encoder.resnet_encoder.6.0              | BasicBlock        | 919 K \n",
      "37 | resnet_encoder.resnet_encoder.6.0.conv1        | Conv2d            | 294 K \n",
      "38 | resnet_encoder.resnet_encoder.6.0.bn1          | BatchNorm2d       | 512   \n",
      "39 | resnet_encoder.resnet_encoder.6.0.relu         | ReLU              | 0     \n",
      "40 | resnet_encoder.resnet_encoder.6.0.conv2        | Conv2d            | 589 K \n",
      "41 | resnet_encoder.resnet_encoder.6.0.bn2          | BatchNorm2d       | 512   \n",
      "42 | resnet_encoder.resnet_encoder.6.0.downsample   | Sequential        | 33 K  \n",
      "43 | resnet_encoder.resnet_encoder.6.0.downsample.0 | Conv2d            | 32 K  \n",
      "44 | resnet_encoder.resnet_encoder.6.0.downsample.1 | BatchNorm2d       | 512   \n",
      "45 | resnet_encoder.resnet_encoder.6.1              | BasicBlock        | 1 M   \n",
      "46 | resnet_encoder.resnet_encoder.6.1.conv1        | Conv2d            | 589 K \n",
      "47 | resnet_encoder.resnet_encoder.6.1.bn1          | BatchNorm2d       | 512   \n",
      "48 | resnet_encoder.resnet_encoder.6.1.relu         | ReLU              | 0     \n",
      "49 | resnet_encoder.resnet_encoder.6.1.conv2        | Conv2d            | 589 K \n",
      "50 | resnet_encoder.resnet_encoder.6.1.bn2          | BatchNorm2d       | 512   \n",
      "51 | resnet_encoder.resnet_encoder.7                | Sequential        | 8 M   \n",
      "52 | resnet_encoder.resnet_encoder.7.0              | BasicBlock        | 3 M   \n",
      "53 | resnet_encoder.resnet_encoder.7.0.conv1        | Conv2d            | 1 M   \n",
      "54 | resnet_encoder.resnet_encoder.7.0.bn1          | BatchNorm2d       | 1 K   \n",
      "55 | resnet_encoder.resnet_encoder.7.0.relu         | ReLU              | 0     \n",
      "56 | resnet_encoder.resnet_encoder.7.0.conv2        | Conv2d            | 2 M   \n",
      "57 | resnet_encoder.resnet_encoder.7.0.bn2          | BatchNorm2d       | 1 K   \n",
      "58 | resnet_encoder.resnet_encoder.7.0.downsample   | Sequential        | 132 K \n",
      "59 | resnet_encoder.resnet_encoder.7.0.downsample.0 | Conv2d            | 131 K \n",
      "60 | resnet_encoder.resnet_encoder.7.0.downsample.1 | BatchNorm2d       | 1 K   \n",
      "61 | resnet_encoder.resnet_encoder.7.1              | BasicBlock        | 4 M   \n",
      "62 | resnet_encoder.resnet_encoder.7.1.conv1        | Conv2d            | 2 M   \n",
      "63 | resnet_encoder.resnet_encoder.7.1.bn1          | BatchNorm2d       | 1 K   \n",
      "64 | resnet_encoder.resnet_encoder.7.1.relu         | ReLU              | 0     \n",
      "65 | resnet_encoder.resnet_encoder.7.1.conv2        | Conv2d            | 2 M   \n",
      "66 | resnet_encoder.resnet_encoder.7.1.bn2          | BatchNorm2d       | 1 K   \n",
      "67 | resnet_encoder.resnet_encoder.8                | AdaptiveAvgPool2d | 0     \n",
      "68 | decoder                                        | Sequential        | 7 M   \n",
      "69 | decoder.0                                      | Conv2d            | 7 M   \n",
      "70 | decoder.1                                      | BatchNorm2d       | 1 K   \n",
      "71 | decoder.2                                      | ReLU              | 0     \n",
      "72 | decoder.3                                      | AdaptiveAvgPool2d | 0     \n",
      "73 | clf                                            | Linear            | 1 K   \n",
      "74 | criterion                                      | BCEWithLogitsLoss | 0     \n",
      "/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:23: UserWarning: Checkpoint directory /scratch/mz2476/DL/project/ssl_project/ssl_ideas/lightning_logs/version_9571145/checkpoints exists and is not empty with save_top_k != 0.All files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bff6b88b8bc49e2b76185b73a750f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ShuffleAndLearnModel()\n",
    "trainer = pl.Trainer(gpus=1)    \n",
    "trainer.fit(model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'callbacks': [<pytorch_lightning.callbacks.progress.ProgressBar at 0x2ac2ae1a15e0>],\n",
       " 'benchmark': False,\n",
       " 'num_nodes': 1,\n",
       " 'log_gpu_memory': None,\n",
       " 'gradient_clip_val': 0,\n",
       " 'check_val_every_n_epoch': 1,\n",
       " 'track_grad_norm': -1,\n",
       " 'on_gpu': True,\n",
       " 'on_tpu': False,\n",
       " 'num_tpu_cores': None,\n",
       " 'num_processes': 1,\n",
       " 'process_position': 0,\n",
       " 'weights_summary': 'full',\n",
       " 'max_epochs': 1000,\n",
       " 'min_epochs': 1,\n",
       " 'max_steps': None,\n",
       " 'min_steps': None,\n",
       " 'num_sanity_val_steps': 5,\n",
       " 'reload_dataloaders_every_epoch': False,\n",
       " 'auto_lr_find': False,\n",
       " 'replace_sampler_ddp': True,\n",
       " 'truncated_bptt_steps': None,\n",
       " 'resume_from_checkpoint': None,\n",
       " 'terminate_on_nan': False,\n",
       " 'shown_warnings': set(),\n",
       " 'fast_dev_run': False,\n",
       " 'default_root_dir': '/scratch/mz2476/DL/project/ssl_project/ssl_ideas',\n",
       " 'total_batch_idx': 833,\n",
       " 'running_loss': <pytorch_lightning.trainer.supporters.TensorRunningAccum at 0x2ac2aeff3d00>,\n",
       " 'batch_idx': 138,\n",
       " 'progress_bar_metrics': {},\n",
       " 'callback_metrics': {'loss': tensor(9.6165, device='cuda:0'),\n",
       "  'train_loss': tensor(9.6165, device='cuda:0'),\n",
       "  'val_loss': tensor(0.6326, device='cuda:0'),\n",
       "  'val_acc': tensor(0.6649, device='cuda:0'),\n",
       "  'epoch': 4},\n",
       " 'num_val_batches': 70,\n",
       " 'num_training_batches': 139,\n",
       " 'num_test_batches': 0,\n",
       " 'train_dataloader': <torch.utils.data.dataloader.DataLoader at 0x2ac2af03ca30>,\n",
       " 'test_dataloaders': None,\n",
       " 'val_dataloaders': [<torch.utils.data.dataloader.DataLoader at 0x2ac29bb7db80>],\n",
       " 'model': ShuffleAndLearnModel(\n",
       "   (resnet_encoder): encoder(\n",
       "     (resnet_encoder): Sequential(\n",
       "       (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "       (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (2): ReLU(inplace=True)\n",
       "       (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "       (4): Sequential(\n",
       "         (0): BasicBlock(\n",
       "           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "         (1): BasicBlock(\n",
       "           (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (5): Sequential(\n",
       "         (0): BasicBlock(\n",
       "           (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (downsample): Sequential(\n",
       "             (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "             (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): BasicBlock(\n",
       "           (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (6): Sequential(\n",
       "         (0): BasicBlock(\n",
       "           (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (downsample): Sequential(\n",
       "             (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "             (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): BasicBlock(\n",
       "           (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (7): Sequential(\n",
       "         (0): BasicBlock(\n",
       "           (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (downsample): Sequential(\n",
       "             (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "             (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           )\n",
       "         )\n",
       "         (1): BasicBlock(\n",
       "           (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "           (relu): ReLU(inplace=True)\n",
       "           (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "           (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "         )\n",
       "       )\n",
       "       (8): AdaptiveAvgPool2d(output_size=(8, 8))\n",
       "     )\n",
       "   )\n",
       "   (decoder): Sequential(\n",
       "     (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "     (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU(inplace=True)\n",
       "     (3): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   )\n",
       "   (clf): Linear(in_features=512, out_features=2, bias=True)\n",
       "   (criterion): BCEWithLogitsLoss()\n",
       " ),\n",
       " 'testing': False,\n",
       " 'disable_validation': False,\n",
       " 'lr_schedulers': [],\n",
       " 'optimizers': [Adam (\n",
       "  Parameter Group 0\n",
       "      amsgrad: False\n",
       "      betas: (0.9, 0.999)\n",
       "      eps: 1e-08\n",
       "      lr: 0.02\n",
       "      weight_decay: 0\n",
       "  )],\n",
       " 'optimizer_frequencies': [],\n",
       " 'global_step': 833,\n",
       " 'current_epoch': 5,\n",
       " 'interrupted': True,\n",
       " 'logger': <pytorch_lightning.loggers.tensorboard.TensorBoardLogger at 0x2ac2af01bac0>,\n",
       " 'profiler': <pytorch_lightning.profiler.profilers.PassThroughProfiler at 0x2ac2af01b8e0>,\n",
       " 'early_stop_callback': None,\n",
       " 'enable_early_stop': False,\n",
       " 'checkpoint_callback': <pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint at 0x2ac2af00a280>,\n",
       " 'weights_save_path': '/scratch/mz2476/DL/project/ssl_project/ssl_ideas/lightning_logs/version_9571145/checkpoints',\n",
       " 'accumulate_grad_batches': 1,\n",
       " 'accumulation_scheduler': <pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler at 0x2ac2af01b9d0>,\n",
       " 'gpus': 1,\n",
       " 'data_parallel_device_ids': [0],\n",
       " 'root_gpu': 0,\n",
       " 'root_device': device(type='cpu'),\n",
       " 'use_tpu': False,\n",
       " 'tpu_local_core_rank': None,\n",
       " 'tpu_global_core_rank': None,\n",
       " 'distributed_backend': None,\n",
       " 'use_dp': False,\n",
       " 'use_ddp': False,\n",
       " 'use_ddp2': False,\n",
       " 'use_horovod': False,\n",
       " 'single_gpu': True,\n",
       " 'proc_rank': 0,\n",
       " 'world_size': 1,\n",
       " 'node_rank': 0,\n",
       " 'is_slurm_managing_tasks': False,\n",
       " 'progress_bar_refresh_rate': 1,\n",
       " 'progress_bar_callback': <pytorch_lightning.callbacks.progress.ProgressBar at 0x2ac2ae1a15e0>,\n",
       " 'log_save_interval': 100,\n",
       " 'val_check_interval': 1.0,\n",
       " 'row_log_interval': 10,\n",
       " 'overfit_pct': 0.0,\n",
       " 'train_percent_check': 1.0,\n",
       " 'val_percent_check': 1.0,\n",
       " 'test_percent_check': 1.0,\n",
       " 'autocast_original_forward': None,\n",
       " 'use_native_amp': False,\n",
       " 'precision': 32,\n",
       " 'amp_level': 'O1',\n",
       " 'ckpt_path': '/scratch/mz2476/DL/project/ssl_project/ssl_ideas/lightning_logs/version_9571145/checkpoints',\n",
       " 'val_check_batch': 139,\n",
       " 'batch_loss_value': <pytorch_lightning.trainer.supporters.TensorRunningAccum at 0x2ac2af021580>,\n",
       " 'hiddens': None,\n",
       " 'split_idx': 0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.__dict__\n",
    "\n",
    "# save best model weights\n",
    "# tensorboard\n",
    "# print log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Launching TensorBoard..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'cgi' has no attribute 'escape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-167e450cd686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start tensorboard.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorboard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--logdir lightning_logs/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_start_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_start_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m   \u001b[0;34m\"\"\"Implementation of the `%tensorboard` line magic.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(args_string)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStartLaunched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     _display(\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mprint_message\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_display\u001b[0;34m(port, height, print_message, display_handle)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0m_CONTEXT_NONE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_display_cli\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m   }[_get_context()]\n\u001b[0;32m--> 316\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_handle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/pDL/lib/python3.8/site-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36m_display_ipython\u001b[0;34m(port, height, display_handle)\u001b[0m\n\u001b[1;32m    381\u001b[0m   \"\"\"\n\u001b[1;32m    382\u001b[0m   replacements = [\n\u001b[0;32m--> 383\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0;34m\"%HTML_ID%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcgi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0;34m\"%JSON_ID%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m       \u001b[0;34m(\u001b[0m\u001b[0;34m\"%PORT%\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cgi' has no attribute 'escape'"
     ]
    }
   ],
   "source": [
    "# Start tensorboard.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-21-1ac3f00228d1>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> up\n",
      "*** Oldest frame\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
